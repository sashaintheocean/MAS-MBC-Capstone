{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dedebc91-15b9-407c-8201-acbc314d3bd7",
   "metadata": {},
   "source": [
    "# Given a dataframe of contaminations, search the Alaska Satellite Facility for matching satellite imagery results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a6f02-b3a4-4534-98af-03d9fb8918d3",
   "metadata": {},
   "source": [
    "**‚≠ê Connect to the ASF API via your username and password**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a854e26c-4405-4665-9523-bdfc13ba88c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Username: aglevy15\n",
      "Password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import asf_search as asf\n",
    "\n",
    "username = input('Username:')\n",
    "password = getpass.getpass('Password:')\n",
    "\n",
    "try: \n",
    "    user_pass_session = asf.ASFSession().auth_with_creds(username, password)\n",
    "except asf.ASFAuthenticationError as e:\n",
    "    print(f'Auth Failed: {e}')\n",
    "else:\n",
    "    print('Success!')\n",
    "\n",
    "session=asf.ASFSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6700f-82d6-4064-8b9c-6b9533e3ffa1",
   "metadata": {},
   "source": [
    "**‚≠ê For a given dataframe, search ASF for matching images based on spill date + 4 days, latitute and longitude**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62b124-3c67-4ea8-9c06-7e004a07849b",
   "metadata": {},
   "source": [
    "**Create a dictionary that returns all contaminations searched with some key high-level identifying features and their ASF results. ASF results includes a scene ID which is searchable in Vertex, an RBG JPG and a ZIP file link to download the entirety of the ASF search results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33835881-3d97-4ee1-8536-791501784920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asf_search.constants as asf_constants\n",
    "import warnings\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import random\n",
    "from requests.exceptions import RequestException\n",
    "import pandas as pd\n",
    "\n",
    "def search_asf_images(df, spill_id = 'Spill ID', start_date='Spill Date', end_date='Case Closed Date', lat_col='Latitude', lon_col='Longitude'):\n",
    "    \n",
    "    #surpress this specific warning as we know our datetimes are correctly formatted\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Parsing dates involving a day of month without a year specified\")\n",
    "    \n",
    "    asf_constants.INTERNAL.CMR_TIMEOUT = 60 \n",
    "    results_with_url = []\n",
    "    max_retries=3\n",
    "\n",
    "    #loop through the dataframe to get values to search for in ASF\n",
    "    for _, row in df.iterrows():\n",
    "        results= []\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                lat = float(row[lat_col])\n",
    "                lon = float(row[lon_col])\n",
    "                start = pd.to_datetime(row[start_date], errors='coerce')\n",
    "                end = start + pd.Timedelta(days=4) \n",
    "                \n",
    "                #if using end_date instead of start+1, check if end is empty and if so, default to 1 day after start \n",
    "                #end = pd.to_datetime(row[end_date])  \n",
    "                #if pd.isna(end):\n",
    "                   #end = start + pd.Timedelta(days=1)\n",
    "                \n",
    "                aoi = f\"POINT({lon} {lat})\"\n",
    "             \n",
    "                # Query ASF API\n",
    "                opts = {\n",
    "                    'platform': asf.PLATFORM.SENTINEL1,\n",
    "                    'processingLevel': asf.PRODUCT_TYPE.GRD_HD,\n",
    "                    'start': start,\n",
    "                    'end': end\n",
    "                }\n",
    "                results=asf.geo_search(intersectsWith=aoi, **opts) \n",
    "                \n",
    "                break #success, exist retry loop\n",
    "                                \n",
    "            except Exception as e:\n",
    "                if \"CMR\" in str(e) or \"timeout\" in str(e).lower():\n",
    "                    print(f\"üåê Timeout on row {row.name}, retrying in a few seconds...\")\n",
    "                    time.sleep(random.randint(3, 6))\n",
    "                    retries += 1\n",
    "                else:\n",
    "                    print(f\"‚ùå Failed on row {row.name}: {e}\")\n",
    "                    break  # fail for other errors\n",
    "        if retries == max_retries:\n",
    "            print(f\"Max retries exeeded for row {row.name}\")\n",
    "            continue \n",
    "\n",
    "        #if there are no ASF results, populate asf_results with empty\n",
    "        if len(results)==0:\n",
    "            results_with_url.append({\n",
    "                'Spill ID': row[spill_id],\n",
    "                'Spill Date': row[start_date],\n",
    "                'ASF Results': []\n",
    "        })\n",
    "    \n",
    "        #else there are multiple results for the scene ID, append to the asf results dict \n",
    "        else: \n",
    "            asf_results=[]\n",
    "            for result in results:\n",
    "                asf_results.append({\n",
    "                    'Scene ID': result.properties['sceneName'],\n",
    "                    'RBG_URL': result.properties['browse'],\n",
    "                    'zip': result.properties['url']\n",
    "                })\n",
    "            results_with_url.append({\n",
    "                'Spill ID': row[spill_id],\n",
    "                'Spill Date': row[start_date],\n",
    "                'ASF Results':asf_results\n",
    "            })\n",
    "                \n",
    "    empty_count = sum(\n",
    "        1 for row in results_with_url \n",
    "        if not row.get('ASF Results')  # catches [], None, ''\n",
    "        )\n",
    "    \n",
    "    print(f\"Empty ASF Results count: {empty_count}\")\n",
    "    #return a dictionary with all the data\n",
    "    return results_with_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4806c0-dfa9-4bc7-a92b-b550257b245e",
   "metadata": {},
   "source": [
    "**Recommendation: search only a small subset of datapoints before running a large query on ASF. You can do this by running on ocean_df.head(n) to search for n number of rows instead of the entire dataframe**\n",
    "\n",
    "**Adding %store -r allows you to access the dataframe from notebook 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8ed6e9-4e6e-4f18-b15d-28efa6de07e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty ASF Results count: 169\n"
     ]
    }
   ],
   "source": [
    "%store -r ocean_df\n",
    "\n",
    "results = search_asf_images(ocean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009ecc4-6b36-4c28-96e8-62fb6c0c0aeb",
   "metadata": {},
   "source": [
    "**‚≠ê The number spills that have no ASF results will display after running!**\n",
    "\n",
    "**To return results as a dataframe:** \n",
    "```results_df = pd.DataFrame(results)```\n",
    "\n",
    "**To download your results into the a folder in the same directory:** \n",
    "```results_df.to_csv(\"asf_adec_search_results.csv\", index=False)```\n",
    "\n",
    "**Special tip: if you're unsure where the CSV is saving, run this code to figure out what directory your csv is saving to :** \n",
    "```import os print(os.getcwd())```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d82731-d58c-48c4-959e-5ed72c63dc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
